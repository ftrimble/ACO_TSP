\documentclass[twocolumn]{article}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{fancyhdr}
\usepackage{algpseudocode}
\usepackage{verbatim}
\usepackage{url}
\usepackage[toc,page]{appendix}

\setlength{\parskip}{5pt plus1pt minus1pt}

\DeclareMathSizes{36}{36}{36}{36}

\title{Massively Parallel Ant Colony Optimization Applied to the Traveling Salesman Problem}
\author{Forest Trimble, Scott Todd\\trimbf@rpi.edu, todds@rpi.edu}

\begin{document}

\maketitle

\pagestyle{fancy}
\fancyhead{}
\fancyhead[L]{Trimble, Todd}
\fancyhead[C]{Massively Parallel ACO on the TSP}
\fancyhead[R]{\today}


\begin{abstract}
  \emph{NP-complete problems have often fascinated programmers and mathematicians alike
  for their difficulty, and the traveling salesman problem is no exception. We 
  study ant colony optimization, a naturally inspired optimization algorithm,
  as applied to the traveling salesman problem. We present an overview of
  the traveling salesman problem and the ant colony optimization algorithm before
  parallelizing it to run on the Blue Gene/Q and analyzing its performance. }
\end{abstract}

\section{Background} \label{sec:tsp}

The traveling salesman problem (TSP) is an extensively-studied NP-complete problem 
in theoretical computer science with varied applications throughout delivery, 
transportation, planning, and logistic operations. In the formulation of the 
problem, a list of cities is given and the distances between each pair of cities
is known. The question, then, is: what is the shortest possible path from city to
city that visits each city exactly once? In particular, this paper 
is concerned with the symmetric
traveling salesman problem, where the distance from any city A to any city B
is the same as the distance from city B to city A. In this case, the problem
can be modeled as an undirected graph, with vertices representing cities and
edges representing paths between cities. For interests' sake, Figure \ref{fig:opt2392}
shows the optimal tour of 2392 cities for such a case. While it is difficult 
(even impossible) to see how to subtract distance from the tour, it is also 
immensely difficult to discern any sort of strategy to arrive at the solution. 
Indeed, this is due to the computational difficulty of the problem.

\begin{figure}
  \centering
  \includegraphics[height=2.2in]{plots/pr2392.eps}
  \caption{An Optimal TSP Tour of 2392 Cities} \label{fig:opt2392}
\end{figure}

The brute force approach to the TSP, which checks each possible solution, takes 
on the order of $\mathcal{O}(n!)$ time. Brute force is generally a pretty poor choice of
algorithm, and that is no different here: as it stands, the most efficient 
exact algorithms, which provably return the optimal solution, use dynamic
programming and operate in $\mathcal{O}(n^22^n)$ time and $\mathcal{O}(2^n)$ space. 
This is a massive time improvement, but it is still computationally intractable, as 
these large run-times and space requirements are prohibitively expensive even on 
supercomputer-class machines. Because of this, a large number of approximation 
algorithms have been formulated that are able to quickly approach the optimal 
solution, some provably within a certain threshold or with a high probability of
being particularly close to the optimal solution.  

The ant colony optimization algorithm (ACO) for the traveling salesman problem 
is one such approximation algorithm which lends itself well to parallel 
computation. It was first proposed by Marco Dorigo's PhD thesis in 1992 \cite{dorigo}. 
Inspiration for this technique comes from the natural world, where ants in a
colony wander seemingly aimlessly until they come across food, leaving
a trail of pheromones for other ants to detect and follow. Pheromones
evaporate over time, so shorter paths accumulate pheromones in a higher density 
more reliably than longer paths. An emergent property of this behavior is that 
efficient paths to food sources will become apparent as more ants wander and 
follow these trails over time. Interestingly, the natural world provides a number
of such heuristics for optimization problems; the interested reader should 
refer to \cite{nature} for an overview of a few of them. 

Just as these ants are able to find efficient routes to their food sources by
utilizing this emergent behavior, computers are able to find short paths through
graphs for the TSP by simulating ants and their pheromone trails. 

An added advantage to the ACO, which is not explored here, is that
the virtual ants are able to adapt to changes in their environment and 
dynamically adjust their preferred path around newly introduced obstacles 
\cite{iridia:aco}.

\section{Ant Colony Optimization: the Algorithm} \label{sec:aco}

It is important to understand how ACO works before diving into 
the implementation details. As such, this section delves
into the concepts behind ACO before covering the
specifics of the implementation in section \ref{sub:acoimpl}. 

Ant Colony Optimization is a randomized process that uses a few things to aid
in its probabilistic selection:
\begin{itemize}
\item distances between cities
\item pheromone concentrations along edges ($\tau$)
\item heuristic parameters $\alpha$, $\beta$, and $\rho$
\end{itemize}
Basically, shorter distances and higher pheromone concentrations will
increase the probability that an ant will travel along an edge. The 
heuristic parameters allow for some variation as to how important 
each of these factors is. This is necessary because an effective 
implementation of the ACO for TSP algorithm must balance the tendency
for ants to follow efficient paths with the desire to discover new, 
perhaps more efficient paths. If the simulated ants follow the 
pheromone trails too closely, they may quickly get caught in local
minima. 

The heuristic parameters $\alpha$ and $\beta$ are weights for the distances and 
the pheromones, respectively, and they can be chosen to help avoid this. They 
are used to calculate the probability, $p^k_{ij}$, of an ant following an edge
$ij$ at iteration $k$ according to 
\begin{equation}
p_{ij}^k = \frac{(\tau^k_{ij})^\alpha(d(C_i,C_j)^{-\beta})}{\displaystyle \sum_{i=1}^m 
  (\tau^k_{ij})^\alpha(d(C_i,C_j)^{-\beta})} \label{eq:probs}
\end{equation}
Thus, if $\alpha >> \beta$, the pheromones will factor in far more than the
distances, and vice versa. In order to fully utilize this behavior, 
some researchers have experimented with 
updating the heuristic parameters as the algorithm executes \cite{ipcsit:aco}.

The final heuristic parameter, $\rho$, is used to 
determine how quickly pheromones decay. This is required to ensure that the pheromones do not
drastically overtake the distances in importance and that paths that are not used become 
progressively less and less attractive. Pheromone concentration is calculated as follows:
\begin{equation}
\tau^k_{ij} = \rho \tau^{k-1}_{ij} + \Delta \tau^k_{ij}, \label{eq:phers}
\end{equation}
which means that the base amount will decay by a factor of $\rho$ and each ant
that uses that edge will deposit some $\Delta\tau^k_{ij}$ amount of pheromone on
that edge. In many implementations of this algorithm, the $\Delta\tau^k_{ij}$
value is proportional to the path length of the ant that traveled it \cite{iridia:aco} 
\cite{ipcsit:aco} \cite{jungblut:aco}.  

Given this background, it becomes fairly simple to write out a general 
formula. The algorithm requires a set of $m$ cities, $C$. Given this, 
it repeatedly finds a tour through all the cities, beginning at a random city
(this is important to avoid an overly greedy strategy) 
and selecting the next city by ``rolling the dice'' and
using \eqref{eq:probs} to select the edge. After a tour is found, the 
pheromones are updated. What follows is a precise definition of the algorithm. 

\noindent {\bf The Ant Colony Optimization Algorithm}
\begin{algorithmic}
  \State Given $C, \rho \in (0,1), \alpha > 0, \beta > 0$, where $|C| = m$
  \State Let $\tau$ be an $m \times m$ matrix of ones.
  \State $d = \infty$
  \For{$k = 0,1,2,\ldots $}
    \State Let $C_i = C_{\mbox{{\tiny BEGIN}}}\in C$ randomly
    \State $V = \{ C_i \}$
    \State $d_k = 0$
    \State $\tau_{ij} = \rho \tau_{ij}$
    \While {$V \not = C$}
       \State Let $p \in (0,1)$ randomly
       \State $\displaystyle p_j = \frac{(\tau_{ij}^\alpha)(d(C_i,C_j)^{-\beta})}{\displaystyle 
         \sum_{n=1}^m (\tau_{in}^\alpha) (d(C_i,C_n)^{-\beta})}$
       \State Set $j \in \mathbb{Z}$ s.t. $\displaystyle \sum_{n=1}^j p_n > p$ and 
       $\displaystyle \sum_{n=1}^{j-1} p_n < p$
       \State $d_k = d_k + d(C_i,C_j)$.
       \State $V = V \cup C_j$
       \State $i = j$
    \EndWhile
    \State $d_k = d_k + d(C_i,C_{\mbox{{\tiny BEGIN}}})$
    \State $\tau_{ij} = \tau_{ij} + \Delta \tau_{ij}$
    \State $d = \min (d_k, d)$
  \EndFor 
\end{algorithmic}

This algorithm is lacking in a few respects. First and foremost, end conditions are not present:
in this form it is designed to be run forever, acquiring a better solution (hopefully) at each
iteration. However, this is not how the algorithm is designed to be used, as the idea is to find
a quick solution that is ``close enough.'' Second, $\rho$, $\alpha$, and $\beta$ are left 
arbitrary. These parameters are heuristics: they must be found empirically, and there is much 
debate as to how to use them properly. These issues are discussed in section \ref{sec:opt}.
Finally, this algorithm is not parallel; that is discussed in section \ref{sec:parallel}. 

Consider how this improves over the best exact algorithms available, however. 
Recall from section
\ref{sec:tsp} that the dynamic programming algorithm operates in $\mathcal{O}(n^22^n)$ time
and $\mathcal{O}(2^n)$ space. This is clearly computationally intractable, so the logical
question is: does ACO avoid this problem? To answer this, some performance analysis is 
required. 

First, consider the time requirements. As it stands, the algorithm is repeated 
infinitely, but, as mentioned above, 
this is not a practical solution. Instead, imagine that $k$ has some upper 
bound, $u$, so that the algorithm is repeated no more than $u$ times. Inside of each iteration, 
a tour must be found, which visits every one of $n$ cities. At each of these cities, 
the probability of visiting every remaining city is found, another $n$ steps. Yet each 
probability requires information about every other probability. Then ACO is na\"{i}vely
$\mathcal{O}(un^3)$ in time complexity. 

Next, consider the space requirements. These are much simpler; it requires only analysis 
of the variables. ACO requires the storage of a few variables, but the only things of 
import are the arrays:
\begin{itemize}
\item $C$, a set of cities (size $n$)
\item $\tau$, a set of pheromones (size $n\times n$)
\item $V$, a set of cities (size $\leq n$)
\end{itemize}
Since $\tau$ requires the most space, ACO uses $\mathcal{O}(n^2)$ space. 

Finally, consider the improvement this offers over the exact dynamic programming 
algorithm. It is a reduction of nearly a factor of $\mathcal{O}(2^n)$ in both time
and space, broadening the set of approachable problems significantly. 

\section{ACO on the TSP Implementation} \label{sub:acoimpl}

Implementing the ACO algorithm for the Blue Gene/Q required a few steps. First,
the tour finding algorithm needed to be implemented in computer usable code. 
Next, the algorithm needed to be parallelized for use on the massive scale of
the Blue Gene/Q. Finally, the algorithm needed to be optimized to minimize 
time and maximize accuracy. Some of this was done through heuristic tuning,
other bits required code refactoring. The first part is somewhat trivial
given the algorithm presented in section \ref{sec:aco} (the interested reader 
can refer to the appendix for more information), but parallelization
and optimization yielded some interesting challenges, presented in sections
\ref{sec:parallel} and \ref{sec:opt}, respectively. 


\subsection{Parallelizing the Algorithm}  \label{sec:parallel}

The algorithm lends itself to parallel execution. Indeed, each processor can
represent a single ant. On the small partition of the Blue Gene/Q that is
available, this yields 1024 ants scurrying around trying to find an optimal
TSP path, a veritable colony! Each processor can compute individual tours by
itself, but the parallel aspect comes into play when handling the pheromones.
In order for the algorithm to work successfully, the pheromones need to come from 
all of the ants depositing their pheromones on their trail. Thus, an up-to-date
pheromone matrix is required. 

However, keeping this available at all times is
very resource intensive. The challenge was to balance the algorithm's requirement
of the pheromones with computational resources. Initially, the solution was to
simply allreduce the matrix after each tour, but this became incredibly 
slow as processors scaled out. In order to combat this, the new solution was
to use a hybrid threading/parallel approach. Since eight threads per task has 
proven success on the Blue Gene/Q as an optimal configuration \cite{lolours},
that was the chosen setup. Leveraging the shared memory of threads cut the 
number of allreduces by a factor of eight (although the shared memory overhead
cut into the performance gains), but there was still room for improvement. Each
task now had a ``sub-colony'' of ants working together to find an optimal 
solution, and letting these small groups work on their own for a bit would allow
for slightly more deviation from the norm. Thus, the next step was to have 
each processor attempt to find some number of paths before updating to the global 
pheromone matrix. 

\subsection{Optimizing the Optimization} \label{sec:opt}

The next challenge was in optimizing the algorithm to yield the best possible
results in the shortest possible amount of time. The first problem was that the
algorithm is $\mathcal{O}(n^3)$, a rather large computational investment. Fortunately,
it was fairly simple to reduce it to $\mathcal{O}(n^2)$. To see this, recall that
part of the reason that 
the algorithm takes $\mathcal{O}(n^3)$ time is due to \eqref{eq:probs}, included again
here for clarity:
\[ p_{ij}^k = \frac{(\tau^k_{ij})^\alpha(d(C_i,C_j)^{-\beta})}{\displaystyle \sum_{i=1}^m 
  (\tau^k_{ij})^\alpha(d(C_i,C_j)^{-\beta})} ,\]
which sums
some factors over all $n$ cities. However, this factor is intended to normalize the
probabilities so that they sum to 1, and is equal at each of the $n$ cities that 
use it. Thus, by calculating the denominator of \eqref{eq:probs} before looping through 
all of the cities, a fairly simple time reduction of $\mathcal{O}(n)$ was achieved. 
In fact, the na\"{i}ve approach to \eqref{eq:probs} has a great deal of inefficiencies,
since most of its values are repeated at each of the original $\mathcal{O}(n^3)$ iterations.
By storing a matrix of the numerators, $(\tau^k_{ij})^\alpha(d(C_i,C_j)^{-\beta}))$, they needed to be
calculated only once for each $i,j,k$ set, rather than the initial $\mathcal{O}(n^3)$. Thus,
the final implementation required far fewer floating point operations than the simpler approach.

Further optimization was achieved by threading out these initial computations. Instead of 
having each thread compute the entirety of $\tau^k_{ij}$, it was sufficient to have each
compute only $\frac{1}{t}$ of the matrix, where $t$ is the number of threads. This works
because the pheromone trails are global, so there is no difference between any two ants.
The same philosophy applied to the matrix of numerators mentioned above. \\

Finally, some thought must be given to the heuristic parameters. This paper delves mostly into 
optimizing the selection of $\rho$, as an incorrectly configured $\rho$ can yield poor
results. Consider one possible configuration before the solution presented here. First,
consider the situation when $\rho = 1$. In this case, there is no decay in the pheromones
as the simulation progresses, only a shift in the relative weights. However, this suffers
because pheromones quickly outweigh distances. This begins to force the algorithm to
choose based on pheromones and discounting distances, which can quickly lock in a certain 
tour. Clearly, this is a sub-optimal solution. Instead of using a constant value of $\rho$,
our algorithm uses the input data to decide upon the correct value. The idea is this: at
each iteration, if an ant travels along an edge, it will deposit 
pheromones proportional to the inverse distance of its tour along the edge. 
Thus, if any ant is traveling along an edge, then it will deposit
at least $n\cdot\min_{i,j} d(C_i,C_j)$ pheromones. The idea, then, was to choose 
$\rho$ such that it would neutralize the smallest possible change in pheromone levels:
\[ \rho = \frac{1}{\displaystyle 1+n\cdot\min_{i,j} d(C_i,C_j)}. \]
In this way, paths that were not taken would shrink in attractiveness, while paths that
were taken would not. 

Some additional thought was given to the initial value of $\tau$. In section \ref{sec:aco},
the algorithm was described where $\tau^0_{ij} = 1,\forall i,j$. However,
this had some issues. Consider the case where $n\cdot \max_{i,j} d(C_i,C_j) < 
\epsilon_{\mbox{{\tiny mach}}}$. Here,
there are a few problems. Recall equation \eqref{eq:phers}, included here for clarity:
\[ \tau^k_{ij} = \rho \tau^{k-1}_{ij} + \Delta \tau^k_{ij}. \]
Since computer arithmetic is imperfect, $1 + \epsilon_{\mbox{{\tiny mach}}} = 1$. Thus, 
\[\rho = \frac{1}{\displaystyle 1+n\cdot \min_{i,j} d(C_i,C_j)} = \frac{1}{1} = 1. \]
In this situation, the chosen value of $\rho$ simply degenerates to the poor, 
na\"{i}ve solution. The other problem is that even if $\rho$ successfully works, 
$\Delta \tau^k_{ij} < \epsilon_{\mbox{{\tiny mach}}}$, so $1 + \Delta \tau^k_{ij} = 1$. That is,
there is a delay in the impact of pheromones: the algorithm will perform iterations that 
are just random choices based on distances until 
$\Delta \tau^k_{ij} > \epsilon_{\mbox{{\tiny mach}}}\tau^k_{ij}$. In order to combat this situation,
two things needed to occur: $\rho$ and $\tau^0$ needed to be adjusted to reflect the uniqueness
of the problem. Instead of using 1 as a basis for $\tau^0$ and $\rho$, the updated algorithm
used 
\[ \frac{\displaystyle \sum_{i=1}^n \sum_{j=1}^n d(C_i,C_j)}{n} \]
in place of 1 to calculate both $\rho$ and $\tau^0$. In this manner, the algorithm 
avoids precision errors.

\section{Performance Results}

After working to implement the algorithm successfully, the next step was to
analyze its performance. In order to do so, data sets
for the TSP from TSPLIB \cite{tsplib} were obtained. The sets of cities
there are accompanied by optimal tours, calculated using exact methods, which
aided the analysis. 

In order to thoroughly test the efficacy of massively parallel ACO on the TSP,
a slew of tests were performed. TSPLIB provided a very good library of problems
to use, facilitating extensive testing on a set of cities of size 52, 150,
318, and 417. Some results from the 150 city attempt are in Figures \ref{fig:dist},
\ref {fig:time}, \ref{fig:ourtour} and \ref{fig:opttour}. 

\begin{figure}
  \centering
  \includegraphics[height=2.2in]{plots/data_dist.eps}
  \caption{Distances found in a strong scaling study} \label{fig:dist}
\end{figure}

Figure \ref{fig:dist} shows the impact of scaling out processors in a strong
scaling study. With a bit of insight into how the strong scaling study was
performed, the lack of improvement is perfectly logical. The algorithm dictates
that the work performed by any processor is constant based on the problem given.
That is, a 150 node problem will have each processor find a tour. Thus, the problem
size at any individual iteration for any processor remains constant, regardless of
scale. Since the algorithm is a heuristic, with little ability to test for a truly
optimal solution, strong scaling was then achieved by putting a cap on the maximum
iterations of the algorithm performed according to the parallelism (i.e. if 1 task
is allowed 256 iterations, then 16 tasks are allowed 16 iterations). Accordingly,
at each number of tasks the same number of \emph{total} iterations were performed. 
This explains the lack of definitive improvement as the number of tasks scaled out,
while the randomized nature of the algorithm explains the irregular data. 

\begin{figure}
  \centering
  \includegraphics[height=2.2in]{plots/data_time.eps}
  \caption{Time taken in a strong scaling study} \label{fig:time}
\end{figure}

Although distance saw negligible returns to scale, that is not to say that 
performance did not improve as processors scaled up. Indeed, consider Figure
\ref{fig:time}. It is quite clear that, at the same total number of iterations,
scaling up significantly reduced the time requirements of the algorithm. In fact,
it appears that returns to scale were nearly perfect (note the log-log scale). 
One thing to note is that communication time is likely underestimated here. The
calculated value
includes only time spent on actual allreduces, but it does not take into account
the communication overhead required for shared memory access across threads. 
Nonetheless, it should not be discounted that computation significantly outweighs
the communication time: recall from Section \ref{sec:aco} that in general, the 
algorithm makes $\mathcal{O}(n^2)$ 
computations per iteration, as it must calculate the probability of traveling 
along any edge ($\mathcal{O}(n)$) for every city in the tour ($\mathcal{O}(n)$). 

\begin{figure}[t]
  \centering
  \includegraphics[height=2.2in]{plots/data_tour.eps}
  \caption{An ACO tour for a 150 city TSP} \label{fig:ourtour}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[height=2.2in]{plots/opt_tour.eps}
  \caption{The Optimal Tour (bottom) for a 150 city TSP} 
  \label{fig:opttour}
\end{figure}

Finally, Figures \ref{fig:ourtour} and \ref{fig:opttour} show what is perhaps 
most interesting: the actual tour that the ACO found, and how it compares to 
the optimal tour. As should be expected, they are not identical; indeed, 
they are quite different. Nonetheless, it is evident that the ACO attempt succeeded
in finding a reasonably efficient solution. According to TSPLIB, the optimal solution
has a distance of 6,528, while the tour shown here was from the 1,024 ant case
has a distance of 6,934. The simulation uses a fairly low number of iterations, 
capping at 4 iterations per processor, so yielding results well within 10\% of
optimality is significant. 

\section{Conclusions}

The ACO algorithm is a fairly successful algorithm which does a great deal to 
mitigate the computational complexity of the TSP. Using the algorithm on the
Blue Gene/Q allows for near optimal solutions to immense TSP problems, something
that would take an unfathomable amount of time to solve exactly. 

Nonetheless, it is not without its issues. The most glaring one, of course,
is accuracy. While the solutions that the ACO provided for us were within
reasonable margins (almost always $<10\%$), this $10\%$ may be of great 
import if the problem is to find an optimal tour of an airplane, where every
unit of distance costs an extra \$1,000. Generally, it may be possible to 
decrease the margin of error by running the algorithm for longer, but 
it is also possible that the algorithm might get ``stuck'' in a local 
minimum. 

\section{Future Work}

In testing our implementation of the ACO for TSP algorithm, we fixed the 
heuristic parameters $\alpha$ and $\beta$ to being 1 and 16, respectively. We 
would have liked to analyze the impact of changing these parameters on the
quality of our results, and to experiment with dynamically
updating these values between iterations, as Zar Chi Su Su Hlaing and May Aye 
Khine did in their research \cite{ipcsit:aco}. Such a study has the possibility
of greatly increasing the convergence speed, as well as helping to avoid 
possible local minima. 

While we did perform a fair amount of optimization, we would like to see the
code run even faster. Taking an $\mathcal{O}(n^22^n)$ problem and finding 
near optimal solutions in $\mathcal{O}(n^2)$ time is quite impressive, but
the need for speed is insatiable.

Given more resources, whether time or processors, we would have liked to run 
larger tests, such as a 128 node, 2,000 iteration test on a 2,392 city TSP 
problem. Problems like these are where using an algorithm like ACO really
shines, as an $\mathcal{O}(n^22^n)$ algorithm requires many orders of 
magnitude more time than the span of the universe.

It would also be interesting to compare the ACO algorithm against other
inexact optimization algorithms, especially the naturally inspired ones
such as particle swarm. 

\section{Related Work}

Ivan Brezina Jr. and Zuzana \v{C}i\v{c}kov\'{a} \cite{mis:aco} studied the 
impact of the various control parameters on the quality of the solutions 
produced for the ACO for TSP algorithm. They found that with $\alpha=1$ and 
$\beta=5$, 10,000 ants were able to approximate the optimal solution to a 32 city
problem within 0.83\% over 242 iterations. 

Marco Dorigo and Luca Maria Gambardella \cite{iridia:aco} modelled local and 
global pheromone trails in their implementation of the ACO for TSP algorithm. 
The global pheromone trail was updated by only the ant with the shortest tour. 
The local pheromone trails were motivated by trail evaporation and were designed
to avoid all ants choosing a very strong edge. They found their algorithm was 
able to find good solutions to the TSP for both symmetric and asymmetric graphs.
They also indicated a few techniques that could be employed to improve upon the 
algorithm in the future, including local optimization heuristics where each ant 
would arrive at a local maximum before updating the trail and parallelizing the
algorithm. 

Zar Chi Su Su Hlaing and May Aye Khine \cite{ipcsit:aco} expanded on the basic 
ACO algorithm by strategically distributing ants and monitoring information 
entropy to update the heuristic parameters as the simulation progressed. 
Compared to other optimizations, such as control of search construction and 
partitioned groups of ants, they found that their proposed algorithm had the 
potential to greatly increase the convergence speed of the ACO algorithm. 

\nocite{*}
\bibliographystyle{plain}
\bibliography{findings}

\begin{appendices}

This section includes the actual source code used to solve the ACO for the TSP 
problem. Included here is only the source code used directly to solve the optimization
problem, but the interested reader can refer to the git repository 
(\url{http://github.com/ftrimble/CSCI-4320-Project}) of this project
in order to see the scripts that generated the graphs, started the runs for the 
Blue Gene/Q, etc. The following pages are the source code for the optimization routine.

\onecolumn

\verbatiminput{src/aco_tsp.c}

\end{appendices}

\end{document}
