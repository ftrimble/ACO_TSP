\documentclass[twocolumn]{article}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{fancyhdr}
\usepackage{algpseudocode}

\DeclareMathSizes{36}{36}{36}{36}

\title{Massively Parallel Ant Colony Optimization Applied to the Travelling Salesman Problem}
\author{Forest Trimble, Scott Todd\\trimbf@rpi.edu, todds@rpi.edu}

\begin{document}

\maketitle

\pagestyle{fancy}
\fancyhead{}
\fancyhead[L]{Trimble, Todd}
\fancyhead[C]{Massively Parallel ACO on the TSP}
\fancyhead[R]{\today}


\begin{abstract}
  \emph{NP-complete problems have often fascinated programmers and mathematicians alike
  for their difficulty, and the traveling salesman problem is no exception. We 
  study ant colony optimization as applied to the traveling salesman problem, 
  and run and analyze its performance on the Blue Gene/Q. }
\end{abstract}

\section{Background}

\subsection{The Travelling Salesman Problem}

The travelling salesman problem (TSP) is an extensively-studied NP-complete problem 
in theoretical computer science with varied applications throughout delivery, 
transportation, planning, and logistic operations. In the formulation of the 
problem, a list of cities is given and the distances between each pair of cities
is known. The question is then: what is the shortest possible path from city to
city that visits each city exactly once? In particular, we studied the symmetric
travelling talesman problem, where the distance from any city A to any city B
is the same as the distance from city B to city A. In this case, the problem
can be modeled as an undirected graph, with vertices representing cities and
edges representing paths between cities.\\

The brute force approach to the TSP, which checks each possible solution, takes 
on the order of $O(n!)$ time. Brute force is generally a pretty poor choice of
algorithm, and that is no different here: as it stands, the most efficient exact 
algorithms (algorithms which provably return the optimal solution) use dynamic
programming and operate in $O(n^22^n)$ time and $O(2^n)$ space. 
This is a massive time improvement, but it is still computationally intractable: 
these large runtimes and space requirements are prohibitively expensive even on 
supercomputer-class machines. Because of this, a large number of approximation 
algorithms have been formulated that are able to quickly approach the optimal 
solution, some provably within a certain threshold or with a high probability of
being particularly close to the optimal solution. 

\subsection{Ant Colony Optimization} \label{sub:aco}

The Ant Colony Optimization algorithm (ACO) for the travelling salesman problem 
is one such approximation algorithm which lends itself well to parallel 
computation. It was first proposed by Marco Doringo's PhD thesis in 1992 % do you have a citation for this?
. The 
inspiration for this technique comes from the natural world, where ants in a
colony wander seemingly aimlessly until they come across food, at which point
they leave a trail of pheromones for other ants to detect and follow. Pheromones
evaporate over time, so shorter paths accumulate pheromones in a higher density 
more reliably than longer paths. An emergent property of this behavior is that 
efficient paths to food sources will become apparent as more ants wander and 
follow these trails over time. Interestingly, the natural world provides a number
of such heuristics for optimization problems.\\

Just as these ants are able to find efficient routes to their food sources by
utilizing this emergent behavior, computers are able to find short paths through
graphs for the TSP by simulating ants and their pheromone trails. \\

Ant Colony Optimization is a randomized process that uses a few things to aid
in its probabilistic selection:
\begin{itemize}
\item distances between cities
\item pheromone concentrations along edges ($\tau$)
\item heuristic parameters $\alpha$, $\beta$, and $\rho$
\end{itemize}
Basically, shorter distances and higher pheromone concentrations will
increase the probability that an ant will travel along an edge. The 
heuristic parameters allow for some variation as to how important 
each of these factors is. This is necessary because an effective 
implementation of the ACO for TSP algorithm must balance the tendency
for ants to follow efficient paths with the desire to discover new, 
perhaps more efficient paths. If the simulated ants follow the 
pheromone trails too closely, they may quickly get caught in local
minima. \\

The heuristic parameters $\alpha$ and $\beta$ are weights for the distances and 
the pheromones, respectively, and they can be chosen to help avoid this. They 
are used to calculate the probability, $p^k_{ij}$, of an ant following an edge
$ij$ at iteration $k$ according to 
\[ p_{ij}^k = \frac{(\tau^k_{ij})^\alpha(d(C_i,C_j)^-\beta)}{\sum_{i=1}^m 
  (\tau^k_{ij})^\alpha(d(C_i,C_j)^{-\beta})} \]
Thus, if $\alpha >> \beta$, the pheromones will factor in far more than the
distances. When $\beta >> \alpha$, the same is true only if the distances are 
normalized to the range $[0,1]$; otherwise $\|\beta\|$ is effective only in 
weeding out the larger distances. Some researchers have experimented with 
updating the heuristic parameters as the algorithm executes \cite{ipcsit:aco}.\\

The final heuristic parameter, $\rho$, is used to 
determine how quickly pheromones decay. This is required to ensure that the pheromones do not
drastically overtake the distances in importance and that paths that are not used become 
progressively less and less attractive. Pheromone concentration is calculated as follows:
\[ \tau^k_{ij} = \rho \tau^{k-1}_{ij} + \Delta \tau^k_{ij}, \]
which means that the base amount will decay by a factor of $\rho$ and each ant
that uses that edge will deposit some $\Delta\tau^k_{ij}$ amount of pheromone on
that edge. In many implementations of this algorithm, the $\Delta\tau^k_{ij}$
value is proportional to the path length travelled by ant $k$. \\ % reference????

What follows is a precise definition of the algorithm. \\

\noindent {\bf The Ant Colony Optimization Algorithm}
\begin{algorithmic}
  \State Given $C, \rho \in (0,1), \alpha > 0, \beta > 0$, where $|C| = m$
  \State Let $\tau$ be an $m \times m$ matrix of ones.
  \State Let $d = \infty$
  \For{$k = 0,1,2,\ldots $}
    \State Let $C_i = C_{\mbox{{\tiny BEGIN}}}\in C$ randomly
    \State $V = \{ C_i \}$
    \State $d_k = 0$
    \While {$V \not = C$}
       \State Let $p \in (0,1)$ randomly
       \State $\displaystyle p_j = \frac{(\tau_{ij}^\alpha)(d(C_i,C_j)^{-\beta})}{\sum_{n=1}^m 
         (\tau_{in}^\alpha) (d(C_i,C_n)^{-\beta})}$
       \State Set $j \in \mathbb{Z}$ s.t. $\displaystyle \sum_{n=1}^j p_n > p$ and 
       $\displaystyle \sum_{n=1}^{j-1} p_n < p$
       \State $d_k = d_k + d(C_i,C_j)$.
       \State $V = V \cup C_j$
       \State $i = j$
    \EndWhile
    \State $d_k = d_k + d(C_i,C_{\mbox{{\tiny BEGIN}}})$
    \State $d = \min (d_k, d)$
    \State $\tau_{ij} = \rho \tau_{ij}$
  \EndFor \\
\end{algorithmic}

This algorithm is lacking in a few respects. First and foremost, end conditions are not present:
in this form it is designed to be run forever, acquiring a better solution (hopefully) at each
iteration. However, this is not how the algorithm is designed to be used, as the idea is to find
a quick solution that is ``close enough.'' Second, $\rho$, $\alpha$, and $\beta$ are left 
arbitrary. These parameters are heuristics: they must be found empirically, and there is much 
debate as to how to use them properly. Finally, this algorithm is not parallel; that is 
discussed in section \ref{sec:parallel}.


\section{Parallel Implementation} \label{sec:parallel}
graphs for the TSP by simulating ants and their pheromone trails. Simulated ants
begin at random vertices in the graph of the particular TSP problem, then find a
path through the graph. The simulated ants decide which edge to follow from a
given vertex by using knowledge of the edge weights (distances) and pheromone
levels along each edge. Ants deposit pheromones while walking the graph. \\


\subsection{Parallelizing the Algorithm}

To parallelize this algorithm, we can have multiple ants complete walks of the
graph in parallel then update the pheromone graph with the combined results of
each ant before starting the next iteration.  \\


\section{Related Articles}

blah...\\


\section{Performance Results}

We performed a strong scaling study, where the problem size remained constant
while the processor count increased.\\


\section{Analysis of Performance Results}

big words go here..\\


\section{Summary and Future Work}

optimistic words and lofty goals go here...\\

\section{Team Member Contributions}

\noindent Forest Trimble coded out and wrote up the actual algorithm.  \\

\noindent Scott Todd set up the base of the code structure, including the input
file parsing and parameter initialization. Prepared input files and testing
materials.

\nocite{*}
\bibliographystyle{plain}
\bibliography{findings}
\end{document}
